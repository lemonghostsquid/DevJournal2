13 February 2015
I have downloaded the screen scraping program; HtmlUnit on my iMac. I went on StackOverflow to learn what to put into the HtmlUnit program. I have also begun downloading NetBeans for my iMac via the tutorial they have on their website. The first screenscrapings will begin next week and I will hopefully be able to have the code for (at least) several SCP files. This progress will help me in creating the program and I am beginning to think that I could add more features of the program. Perhaps a website would be useful for distributing the information to people on the internet. I will also have to consider the aesthetics of the website; I already have some design ideas on paper for the website’s physical appearance. I also have some design ideas for what the GUI will look like. Perhaps I will be able to make a search bar so the user can search for specific files (I still need to research how to do this, but I definitely think that a search feature would be nice).

20 February 2015
I have added additional code to the HtmlUnit and I have begun working on the NetBeans coding. I will probably use Weebly to make my website for the program. Unfortunately I have been set back a bit because my flash drive was corrupted and I had to format it. Despite this, I will definitely be able to get some work done and scrape more files. Also, I have decided to move all of my 20% Project work to a Windows computer, since the Mac OS X is a little bit less friendly to the necessary programs. All of my stuff is now on the windows computer and hopefully there will be less problems regarding compatibility. I have envisioned the GUI having the following: a working search box, anywhere from 200-500 separate SCP files, and a README.txt file that will explain the SCP foundation, classifications, and the actual website. The README.txt will be written to tell the user how to use the program.

27 February 2015
I have created the website via the Weebly website creator, complete with links and information about the whole concept behind the program. I used a cool aesthetic, visual theme that matches the classified, official motif of the SCP Foundation. The website features three separate sections: home, about, and contact (home is the place where the download file will be). The website URL is http://scpfile.weebly.com/. I do realize that it will not be until the end of the project that I will be able to actually have the program on the website, but I am sure that having the website now is better than having it later since it is a fairly easy thing to do. Another thing that I have done is explore the NetBeans Program. Unsurprisingly, the program itself has a fairly complex GUI and I am in the process of exploring all of its features and understanding how it works. I have some pretty great ideas for the program’s GUI.

6 March 2015
I have completed my layout draft of the GUI and it has been turned in and everything. Unfortunately, I have run into some issues with my scraping program HTMLUnitScraper. I am going to ask for some help with it on Monday, and I may have to look into other screen scraping options. WebHarvy and NekoHTML seem like viable options, but I am only going to switch if I absolutely have to. Much of the problem comes from the fact that HTMLUnitScraper lacks a GUI and its file seem to be mainly Internet Explorer web pages. There are literally hundreds of the web pages, and they do not provide any easy directions. The website that I got HTMLUnitScraper from is not very helpful either. Despite these drawbacks, I am sure that all of the necessary work will be done by next Friday, and I am looking forward to asking for help on Monday.

13 March 2015
I have found a completely new program called Jtidy that claims to be simpler and better to use. It seemed that HTMLUnit was made for programmers who have had lots of experience with coding. Jtidy took half as long to download and seems to have much less files. This is good, because there is less stuff that I might mess up. Also, I have decided that the project will only include the first series of SCPs, which would be the first 999 SCP files. I think that 2999 is probably too much to use, and it would greatly lengthen the time it takes to download the file. I recent issue that I have run into is the parts of text that are considered REDACTED. These confidential pieces of information are represented by solid black lines, and I fear that java will not be able to process them (much like how it cannot process certain accented characters).

20 March 2015
Mr. Schreiber was not here on 20% Project day (today, Friday), so I did not get to ask for advice on the scraping programs. I will have to ask on the next Friday that I see him (in two weeks). To better understand the concept of screen scraping, I went to technopedia to find out more. I understand that it is a way to collect screen display data from an application and translate it so that another application can display it. In my case, I will have to “web scrape” from the SCP wiki to get all the data that I need. I assume that the website in question uses the HTML format, since it is a wiki. If I cannot properly scrape the data, I will probably have to ask for help on Piazza, Yahoo Answers, or StackOverflow or simply copy and paste the website data into the program itself.
Mr. Schreiber was not here on 20% Project day (today, friday), so I did not get to ask for advice on the scraping programs.